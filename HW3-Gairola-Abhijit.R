#Q1
X = rnorm(1000,mean = 0, sd = 1)
Y = rnorm(3000,mean = 0, sd = sqrt(5))
Z = c(X,Y)
D.MC = c()
for(i in 1:10000)
{
  Z = sample(Z)
  D.MC = c(D.MC,mean(Z[1:1000]) - mean(Z[1001:4000]))
}
par(mfrow = c(1,2))
D.theoretical = rnorm(10000,mean = 0 , sd = sqrt(1/1000+5/3000))
qqplot(D.MC,D.theoretical,main = "QQplot for m = 1000,n=3000")
abline(a = 0,b = 1)

# from the QQplot, we can see that the distribution statistic calculated on the MC generated samples is different(heavy tailed) from the distribution generated by theory. 
#B

X = rnorm(2000,mean = 0, sd = 1)
Y = rnorm(2000,mean = 0, sd = sqrt(5))
Z = c(X,Y)
D.MC = c()
for(i in 1:10000)
{
  Z = sample(Z)
  D.MC = c(D.MC,mean(Z[1:2000]) - mean(Z[2001:4000]))
}
D.theoretical = rnorm(10000,mean = 0 , sd = sqrt(1/2000+5/2000))
qqplot(D.MC,D.theoretical,main = "QQplot for m=n=2000")
abline(a = 0,b = 1)

# from the QQplot, we can see that the distribution statitic calculated on the MC generated samples is the same as generated by the theory. 

par(mfrow  = c(1,1))
########################################################

#Q2

#a.) The null hypothesis for the run test would be that the number of X-runs would be a random number(or, X and Y are randomly distributed in Z).
# The alternative hypothesis being that the number of X runs is not a random number. 



#b.
library(randtests)
load("cloudseeding.rda")
x = cloudseeding$unseeded
names(x) = c(rep("X",length(x)))
y = cloudseeding$seeded
names(y) = c(rep("Y",length(y)))
z = names(sort(c(x,y)))
z = ifelse((z == "X"),0,1)   # Generating a 0-1 vector based on which class the sample belongs to.
runs.test(z)

# thus, we fail to reject the null that the seeded cloud runs are randomly distributed.
#c.

nb.runs.test = function(x,y,B = 999)
{
  names(x) = c(rep("X",length(x)))
  names(y) = c(rep("Y",length(y)))
  z = names(sort(c(x,y)))
  z = ifelse((z == "X"),0,1)
  run = length(which(diff(z)== 1))
  run = ifelse((z[length(z)] == 0),run+1,run)           # calculating the X-run on the original z-vector
  runs = c()
  for(i in 1:B)
  {
    z.boot = sample(z)
    runs[i] = length(which(diff(z.boot) == 1)) 
    runs[i] = ifelse((z.boot[length(z.boot)] == 0),runs[i]+1,runs[i])
    
  }
  
  p.val = (length(which(runs >= run))+1)/(B+1)
  return(min(2*p.val,2*(1-p.val)))
}
# we can calculate the p-value for the two sided test by calculating the number of X-runs on the original data, then find out the fraction of times the number of X runs of the MC simulation is greater than the X-runs on the original data.
# For the two sided test, we return the minimum of (2*p,2(1-p)). The p-value obtained is not exact because the total number of runs in the MC simulation is smaller than all the possible permutations of the z vector,
# and also because we assume the distribution of the runs is approximately symmetric.

#d.) The one sided version of the test would calculate the p-value the same way as the two sided test, and return the p.value
nb.runs.test.one.sided = function(x,y,B = 999)
{
  names(x) = c(rep("X",length(x)))
  names(y) = c(rep("Y",length(y)))
  z = names(sort(c(x,y)))
  z = ifelse((z == "X"),0,1)
  run = length(which(diff(z)== 1))
  run = ifelse((z[length(z)] == 0),run+1,run)           # calculating the X-run on the original z-vector
  runs = c()
  for(i in 1:B)
  {
    z.boot = sample(z)
    runs[i] = length(which(diff(z.boot) == 1)) 
    runs[i] = ifelse((z.boot[length(z.boot)] == 0),runs[i]+1,runs[i])
    
  }
  
  p.val = (length(which(runs >= run))+1)/(B+1)
  return(p.val)
}


#####################################################
#Q3. 


nb.runs.sym.test = function(x,B = 999)
{
  X = x[x>0]
  Y = -1*x[x<0]
  # we convert the symmetry test to a two sample wald wolfwitz test with the null hypothesis being that the X-runs are randomly distributed.
  p = nb.runs.test.one.sided(X,Y,999)
  return(p)
  
}

#For a low p value from the function nb.runs.test.one.sided,we reject the null that the X-runs are randomly distributed.Thus, for symmetric x,
# we get low p-value from the function nb.runs.sym.test.

#nb.runs.sym.test(seq(-50,50))
#0.001
#nb.runs.sym.test(c(32,1,4,1,-1))
#0.631

